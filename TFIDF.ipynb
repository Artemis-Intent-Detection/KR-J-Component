{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Corpus\n",
    "\n",
    "Reference: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.preprocess import getTFIDFCorpus\n",
    "from utils.utils import getVecForm\n",
    "from utils.models import simpleNN, simpleLSTM\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './Datasets/'\n",
    "DIMS = 300\n",
    "PREPROCESS = 'tfidf'\n",
    "MAXVECLEN = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read GloVe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hites\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=0.001,\n",
       "                tokenizer=<function word_tokenize at 0x000002C2FAF44700>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VEC = getTFIDFCorpus(MaxvecLen=MAXVECLEN)\n",
    "VEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>versace store clerk sue secret black code mino...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roseanne revival catch thorny political mood w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom start fear son web series close thing gran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner want wife listen come alternative debt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rowling wish snape happy birthday magical way</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28608</th>\n",
       "      <td>tyson hold contest let fan submit new idea tor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28609</th>\n",
       "      <td>increasingly cocky bernie sander announce will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28610</th>\n",
       "      <td>cash strap zuckerberg force sell million faceb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28611</th>\n",
       "      <td>grocery store bar actually great little happy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28612</th>\n",
       "      <td>study marathon spectator attend sick thrill wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "0      versace store clerk sue secret black code mino...             0\n",
       "1      roseanne revival catch thorny political mood w...             0\n",
       "2      mom start fear son web series close thing gran...             1\n",
       "3      boehner want wife listen come alternative debt...             1\n",
       "4          rowling wish snape happy birthday magical way             0\n",
       "...                                                  ...           ...\n",
       "28608  tyson hold contest let fan submit new idea tor...             1\n",
       "28609  increasingly cocky bernie sander announce will...             1\n",
       "28610  cash strap zuckerberg force sell million faceb...             1\n",
       "28611  grocery store bar actually great little happy ...             1\n",
       "28612  study marathon spectator attend sick thrill wa...             1\n",
       "\n",
       "[28613 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH+'Sarcasm_Headlines_Detection.csv').dropna().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove excessively long texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>versace store clerk sue secret black code mino...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roseanne revival catch thorny political mood w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom start fear son web series close thing gran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner want wife listen come alternative debt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rowling wish snape happy birthday magical way</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28607</th>\n",
       "      <td>tyson hold contest let fan submit new idea tor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28608</th>\n",
       "      <td>increasingly cocky bernie sander announce will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28609</th>\n",
       "      <td>cash strap zuckerberg force sell million faceb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28610</th>\n",
       "      <td>grocery store bar actually great little happy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28611</th>\n",
       "      <td>study marathon spectator attend sick thrill wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28612 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "0      versace store clerk sue secret black code mino...             0\n",
       "1      roseanne revival catch thorny political mood w...             0\n",
       "2      mom start fear son web series close thing gran...             1\n",
       "3      boehner want wife listen come alternative debt...             1\n",
       "4          rowling wish snape happy birthday magical way             0\n",
       "...                                                  ...           ...\n",
       "28607  tyson hold contest let fan submit new idea tor...             1\n",
       "28608  increasingly cocky bernie sander announce will...             1\n",
       "28609  cash strap zuckerberg force sell million faceb...             1\n",
       "28610  grocery store bar actually great little happy ...             1\n",
       "28611  study marathon spectator attend sick thrill wa...             1\n",
       "\n",
       "[28612 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tooLong = []\n",
    "for i in range(len(df['headline'])):\n",
    "    if len(df['headline'][i].split()) > MAXVECLEN:\n",
    "        tooLong.append(i)\n",
    "for i in tooLong:\n",
    "    df = df.drop(i, axis=0).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, Y_ = df['headline'], df['is_sarcastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset into Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = getVecForm(\n",
    "    X = X_,\n",
    "    Y = Y_,\n",
    "    vec = VEC,\n",
    "    dims=DIMS,\n",
    "    preprocess=PREPROCESS,\n",
    "    vectype='sum',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28612, 1392)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.5833 - accuracy: 0.6843 - val_loss: 0.5673 - val_accuracy: 0.7342\n",
      "Epoch 2/5\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.7970 - val_loss: 0.5333 - val_accuracy: 0.7335\n",
      "Epoch 3/5\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.8416 - val_loss: 0.5612 - val_accuracy: 0.7324\n",
      "Epoch 4/5\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.8918 - val_loss: 0.5851 - val_accuracy: 0.7302\n",
      "Epoch 5/5\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.2034 - accuracy: 0.9293 - val_loss: 0.6404 - val_accuracy: 0.7251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c285270ca0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn = simpleNN(X)\n",
    "snn.fit(x_train, y_train, validation_split=0.3, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 1ms/step - loss: 0.6114 - accuracy: 0.7359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6113747954368591, 0.7359150052070618]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM (sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset into Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = getVecForm(\n",
    "    X = X_,\n",
    "    Y = Y_,\n",
    "    vec = VEC,\n",
    "    dims=DIMS,\n",
    "    preprocess=PREPROCESS,\n",
    "    vectype='sum',\n",
    "    reshaping=(X.shape[0], 1, X.shape[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28612, 1, 1392)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "470/470 [==============================] - 4s 4ms/step - loss: 0.6854 - accuracy: 0.5689 - val_loss: 0.6718 - val_accuracy: 0.6025\n",
      "Epoch 2/10\n",
      "470/470 [==============================] - 2s 4ms/step - loss: 0.6391 - accuracy: 0.7003 - val_loss: 0.6051 - val_accuracy: 0.7373\n",
      "Epoch 3/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.5617 - accuracy: 0.7551 - val_loss: 0.5435 - val_accuracy: 0.7432\n",
      "Epoch 4/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.5073 - accuracy: 0.7667 - val_loss: 0.5140 - val_accuracy: 0.7467\n",
      "Epoch 5/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4785 - accuracy: 0.7742 - val_loss: 0.5024 - val_accuracy: 0.7476\n",
      "Epoch 6/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4629 - accuracy: 0.7770 - val_loss: 0.4990 - val_accuracy: 0.7468\n",
      "Epoch 7/10\n",
      "470/470 [==============================] - 2s 4ms/step - loss: 0.4537 - accuracy: 0.7810 - val_loss: 0.4988 - val_accuracy: 0.7476\n",
      "Epoch 8/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4478 - accuracy: 0.7848 - val_loss: 0.5002 - val_accuracy: 0.7504\n",
      "Epoch 9/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4436 - accuracy: 0.7863 - val_loss: 0.5017 - val_accuracy: 0.7488\n",
      "Epoch 10/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c28aaea400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstms = simpleLSTM(X)\n",
    "lstms.fit(x_train, y_train, validation_split=0.3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5201503038406372, 0.7401090264320374]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstms.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM (vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset into Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = getVecForm(\n",
    "    X = X_,\n",
    "    Y = Y_,\n",
    "    vec=VEC,\n",
    "    dims=DIMS,\n",
    "    preprocess=PREPROCESS,\n",
    "    vectype='vector',\n",
    "    MaxvecLen=MAXVECLEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28612, 30, 1392)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "470/470 [==============================] - 6s 10ms/step - loss: 0.6360 - accuracy: 0.6159 - val_loss: 0.5641 - val_accuracy: 0.7257\n",
      "Epoch 2/10\n",
      "470/470 [==============================] - 4s 8ms/step - loss: 0.5005 - accuracy: 0.7607 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
      "Epoch 3/10\n",
      "470/470 [==============================] - 4s 8ms/step - loss: 0.4670 - accuracy: 0.7869 - val_loss: 0.5231 - val_accuracy: 0.7400\n",
      "Epoch 4/10\n",
      "470/470 [==============================] - 4s 8ms/step - loss: 0.4516 - accuracy: 0.7959 - val_loss: 0.5227 - val_accuracy: 0.7429\n",
      "Epoch 5/10\n",
      "470/470 [==============================] - 4s 8ms/step - loss: 0.4413 - accuracy: 0.7999 - val_loss: 0.5273 - val_accuracy: 0.7429\n",
      "Epoch 6/10\n",
      "470/470 [==============================] - 4s 8ms/step - loss: 0.4320 - accuracy: 0.8037 - val_loss: 0.5338 - val_accuracy: 0.7415\n",
      "Epoch 7/10\n",
      "470/470 [==============================] - 4s 8ms/step - loss: 0.4221 - accuracy: 0.8068 - val_loss: 0.5465 - val_accuracy: 0.7380\n",
      "Epoch 8/10\n",
      "470/470 [==============================] - 4s 8ms/step - loss: 0.4118 - accuracy: 0.8139 - val_loss: 0.5407 - val_accuracy: 0.7446\n",
      "Epoch 9/10\n",
      "470/470 [==============================] - 4s 8ms/step - loss: 0.4021 - accuracy: 0.8147 - val_loss: 0.5685 - val_accuracy: 0.7341\n",
      "Epoch 10/10\n",
      "470/470 [==============================] - 4s 8ms/step - loss: 0.3920 - accuracy: 0.8185 - val_loss: 0.5556 - val_accuracy: 0.7358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c28e0e3880>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmv = simpleLSTM(X)\n",
    "lstmv.fit(x_train, y_train, validation_split=0.3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 1s 4ms/step - loss: 0.5453 - accuracy: 0.7382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.545265257358551, 0.7381518483161926]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmv.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
