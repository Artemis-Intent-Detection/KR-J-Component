{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Corpus\n",
    "\n",
    "Reference: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.preprocess import getWord2VecCorpus\n",
    "from utils.utils import getVecForm\n",
    "from utils.models import simpleNN, simpleLSTM\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './Datasets/'\n",
    "DIMS = 300\n",
    "PREPROCESS = 'word2vec'\n",
    "MAXVECLEN = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read GloVe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1f972b11c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VEC = getWord2VecCorpus()\n",
    "VEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>versace store clerk sue secret black code mino...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roseanne revival catch thorny political mood w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom start fear son web series close thing gran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner want wife listen come alternative debt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rowling wish snape happy birthday magical way</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28608</th>\n",
       "      <td>tyson hold contest let fan submit new idea tor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28609</th>\n",
       "      <td>increasingly cocky bernie sander announce will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28610</th>\n",
       "      <td>cash strap zuckerberg force sell million faceb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28611</th>\n",
       "      <td>grocery store bar actually great little happy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28612</th>\n",
       "      <td>study marathon spectator attend sick thrill wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "0      versace store clerk sue secret black code mino...             0\n",
       "1      roseanne revival catch thorny political mood w...             0\n",
       "2      mom start fear son web series close thing gran...             1\n",
       "3      boehner want wife listen come alternative debt...             1\n",
       "4          rowling wish snape happy birthday magical way             0\n",
       "...                                                  ...           ...\n",
       "28608  tyson hold contest let fan submit new idea tor...             1\n",
       "28609  increasingly cocky bernie sander announce will...             1\n",
       "28610  cash strap zuckerberg force sell million faceb...             1\n",
       "28611  grocery store bar actually great little happy ...             1\n",
       "28612  study marathon spectator attend sick thrill wa...             1\n",
       "\n",
       "[28613 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH+'Sarcasm_Headlines_Detection.csv').dropna().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove excessively long texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>versace store clerk sue secret black code mino...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roseanne revival catch thorny political mood w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom start fear son web series close thing gran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner want wife listen come alternative debt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rowling wish snape happy birthday magical way</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28607</th>\n",
       "      <td>tyson hold contest let fan submit new idea tor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28608</th>\n",
       "      <td>increasingly cocky bernie sander announce will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28609</th>\n",
       "      <td>cash strap zuckerberg force sell million faceb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28610</th>\n",
       "      <td>grocery store bar actually great little happy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28611</th>\n",
       "      <td>study marathon spectator attend sick thrill wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28612 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "0      versace store clerk sue secret black code mino...             0\n",
       "1      roseanne revival catch thorny political mood w...             0\n",
       "2      mom start fear son web series close thing gran...             1\n",
       "3      boehner want wife listen come alternative debt...             1\n",
       "4          rowling wish snape happy birthday magical way             0\n",
       "...                                                  ...           ...\n",
       "28607  tyson hold contest let fan submit new idea tor...             1\n",
       "28608  increasingly cocky bernie sander announce will...             1\n",
       "28609  cash strap zuckerberg force sell million faceb...             1\n",
       "28610  grocery store bar actually great little happy ...             1\n",
       "28611  study marathon spectator attend sick thrill wa...             1\n",
       "\n",
       "[28612 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tooLong = []\n",
    "for i in range(len(df['headline'])):\n",
    "    if len(df['headline'][i].split()) > MAXVECLEN:\n",
    "        tooLong.append(i)\n",
    "for i in tooLong:\n",
    "    df = df.drop(i, axis=0).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, Y_ = df['headline'], df['is_sarcastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset into Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = getVecForm(\n",
    "    X = X_,\n",
    "    Y = Y_,\n",
    "    vec = VEC,\n",
    "    dims=DIMS,\n",
    "    preprocess=PREPROCESS,\n",
    "    vectype='sum',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28612, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.5948 - accuracy: 0.6979 - val_loss: 0.5244 - val_accuracy: 0.7436\n",
      "Epoch 2/5\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5049 - accuracy: 0.7515 - val_loss: 0.5109 - val_accuracy: 0.7515\n",
      "Epoch 3/5\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.4696 - accuracy: 0.7772 - val_loss: 0.5017 - val_accuracy: 0.7560\n",
      "Epoch 4/5\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.4301 - accuracy: 0.8001 - val_loss: 0.5046 - val_accuracy: 0.7578\n",
      "Epoch 5/5\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.3907 - accuracy: 0.8234 - val_loss: 0.5078 - val_accuracy: 0.7608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f9123425b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn = simpleNN(X)\n",
    "snn.fit(x_train, y_train, validation_split=0.3, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.7477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5238915681838989, 0.7476583123207092]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM (sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset into Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = getVecForm(\n",
    "    X = X_,\n",
    "    Y = Y_,\n",
    "    vec = VEC,\n",
    "    dims=DIMS,\n",
    "    preprocess=PREPROCESS,\n",
    "    vectype='sum',\n",
    "    reshaping=(X.shape[0], 1, X.shape[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28612, 1, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "470/470 [==============================] - 4s 4ms/step - loss: 0.6154 - accuracy: 0.6663 - val_loss: 0.5801 - val_accuracy: 0.7032\n",
      "Epoch 2/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.5520 - accuracy: 0.7239 - val_loss: 0.5534 - val_accuracy: 0.7206\n",
      "Epoch 3/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.5268 - accuracy: 0.7417 - val_loss: 0.5434 - val_accuracy: 0.7285\n",
      "Epoch 4/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.5119 - accuracy: 0.7521 - val_loss: 0.5343 - val_accuracy: 0.7359\n",
      "Epoch 5/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4993 - accuracy: 0.7616 - val_loss: 0.5250 - val_accuracy: 0.7366\n",
      "Epoch 6/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4886 - accuracy: 0.7669 - val_loss: 0.5198 - val_accuracy: 0.7392\n",
      "Epoch 7/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4795 - accuracy: 0.7746 - val_loss: 0.5184 - val_accuracy: 0.7418\n",
      "Epoch 8/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4691 - accuracy: 0.7767 - val_loss: 0.5138 - val_accuracy: 0.7456\n",
      "Epoch 9/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4604 - accuracy: 0.7822 - val_loss: 0.5085 - val_accuracy: 0.7491\n",
      "Epoch 10/10\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.4516 - accuracy: 0.7910 - val_loss: 0.5054 - val_accuracy: 0.7533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa64527d00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstms = simpleLSTM(X)\n",
    "lstms.fit(x_train, y_train, validation_split=0.3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5010948777198792, 0.7560464143753052]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstms.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM (vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset into Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = getVecForm(\n",
    "    X = X_,\n",
    "    Y = Y_,\n",
    "    vec = VEC,\n",
    "    dims=DIMS,\n",
    "    preprocess=PREPROCESS,\n",
    "    vectype='vector',\n",
    "    MaxvecLen=MAXVECLEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28612, 30, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "470/470 [==============================] - 4s 7ms/step - loss: 0.6197 - accuracy: 0.6617 - val_loss: 0.5758 - val_accuracy: 0.7164\n",
      "Epoch 2/10\n",
      "470/470 [==============================] - 3s 6ms/step - loss: 0.5455 - accuracy: 0.7404 - val_loss: 0.5420 - val_accuracy: 0.7383\n",
      "Epoch 3/10\n",
      "470/470 [==============================] - 3s 6ms/step - loss: 0.5212 - accuracy: 0.7579 - val_loss: 0.5291 - val_accuracy: 0.7451\n",
      "Epoch 4/10\n",
      "470/470 [==============================] - 3s 6ms/step - loss: 0.5048 - accuracy: 0.7673 - val_loss: 0.5168 - val_accuracy: 0.7538\n",
      "Epoch 5/10\n",
      "470/470 [==============================] - 3s 6ms/step - loss: 0.4894 - accuracy: 0.7770 - val_loss: 0.5085 - val_accuracy: 0.7600\n",
      "Epoch 6/10\n",
      "470/470 [==============================] - 3s 6ms/step - loss: 0.4769 - accuracy: 0.7863 - val_loss: 0.4983 - val_accuracy: 0.7651\n",
      "Epoch 7/10\n",
      "470/470 [==============================] - 3s 6ms/step - loss: 0.4608 - accuracy: 0.7949 - val_loss: 0.4929 - val_accuracy: 0.7695\n",
      "Epoch 8/10\n",
      "470/470 [==============================] - 3s 6ms/step - loss: 0.4448 - accuracy: 0.8017 - val_loss: 0.4873 - val_accuracy: 0.7701\n",
      "Epoch 9/10\n",
      "470/470 [==============================] - 3s 6ms/step - loss: 0.4301 - accuracy: 0.8093 - val_loss: 0.4806 - val_accuracy: 0.7769\n",
      "Epoch 10/10\n",
      "470/470 [==============================] - 3s 6ms/step - loss: 0.4201 - accuracy: 0.8189 - val_loss: 0.4727 - val_accuracy: 0.7774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa7de80b20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmv = simpleLSTM(X)\n",
    "lstmv.fit(x_train, y_train, validation_split=0.3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4732 - accuracy: 0.7808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4732193350791931, 0.7807912826538086]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmv.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
